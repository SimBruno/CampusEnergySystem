---
title: "Energy demand of the EPFL campus"
editor: visual
---


```{r, echo=F, results='hide',label='activate venv'}
#path <- file.path('./venv/bin/python')
library(reticulate)
#use_python(path)
use_virtualenv('./venv', required=FALSE)
```

```{python, echo=F, results='hide', label='load data'}
import matplotlib
matplotlib.use('Agg')
import codes_01_energy_demand.NR_functions as fct1
from codes_01_energy_demand.NR_functions import WeatherClustering
import numpy as np; from numpy import matlib
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering
import os
import plotly.express as px
import plotly.graph_objects as go
from IPython.display import display, HTML
```

```{python, echo=F, results='hide', label='load parameters'}
weather, buildings = fct1.load_data_weather_buildings()
h = 8760  # Hours in a year
T_th = 273 + 16 # Cut off temperature [K]
cp_air = 1152 # Air specific heat capacity [J/(m3.K)] 
T_int = 273 + 21 # Set point temperature [K]
air_new = 2.5 # Air renewal [m3/(m2.h)]
Vent = 0 # [...]
f_el = 0.8 # Share of electricity demand which is converted to heat appliances
```

## Buildings Energy Balance {#subsec:building-energy-balance}

This first section aims to estimate the energy demand of the EPFL campus. For this purpose, the annual energy consumption of the buildings is given, in the following format:

```{python, echo=F, eval=F, results='show'}
#| label: df preview
buildings.head(2)
```

```{r , echo=F, eval=T}
#| label: fig-buildings
#| fig-cap: Buildings data

buildings <- read.csv("codes_01_energy_demand\\Buildings.csv")

library(DT)

col_names<- c("Building", "Constr. year", "Heated surf. [m²]", "Heat cons. [kWh]","Elec cons. [kWh]")

datatable(buildings,
            colnames = col_names,
            options = list(pageLength = 5,scrollX = TRUE)            
)
```


Where $Ground$ is the building surface area in $[m^2]$, $Heat$ is the building annual heating consumption in $[kWh]$, $Elec$ is the building annual electricity consumption in $[kWh]$ and $Year$ is the building group identifier.

Furthermore, the hourly weather data during that year are also available, i.e external temperature and solar irradiation. Thanks to these data, it is possible to characterize the physical properties of the buildings. Performing an energy balance on a building yields the following equation:
$$
Q_\text{th} = A_\text{th} \cdot (k_\text{th} \cdot (T_\text{int} - T_\text{ext}(t)) - k_\text{sun} \cdot i(t) - q_\text{people}(t) - f_\text{el} \cdot q_\text{el}(t))
$${#eq-building-balance}

where:

- $A_\text{th}$: reference heated surface [m<sup>2</sup>]
- $k_\text{th}$: thermal losses and ventilation coefficient in [W/m<sup>2</sup>/K]
- $T_\text{int}$: internal set point temperature equal to 21°C
- $T_\text{ext}(t)$: external ambient temperature [°C]
- $k_\text{sun}$: solar radiation coefficient [-]
- $i(t)$: solar global radiation per area [W/m<sup>2</sup>], given in the project appendice
- $q_\text{people}(t)$: heat gain due to the presence of people per unit area [W/m<sup>2</sup>]
- $f_\text{el}$: share of electricity demand converted to heat appliances [-]
- $q_\text{el}(t)$: Electricity demand [W/m<sup>2</sup>]
- $Q_\text{th}(t)$: Heat load (heating demand when positive, cooling when negative) [W]

The unknowns are $q_\text{people}(t)$, $q_\text{el}(t)$, $k_\text{th}$, and $k_\text{sun}$. To begin with, with the occupancy profile of the buildings, the heat generation from people and the electricity demand will be derived, using the known annual demand.

## Hourly Profiles {#subsec:hourly-profiles}

The electricity profile demand is assumed to be constant when turned on. Electricity is used on weekdays from 7 AM to 9 PM. The values of the uniform electrictiy profile are calculated by dividing the specific electricity consumption of the buildings by the number of operating hours, i.e. 3654 hours per year.


<!-- Generate elec profile -->
```{python, echo=F, results='show'}
#| label: generate profiles
profile_off, profile_class, profile_rest, profile_elec = fct1.occupancy_profile()
```


```{python, eval =T, echo=F, results='show', label='plot profiles', fig.cap='Occupancy profiles'}
fig, axs = plt.subplots(1, 4, figsize=(14, 3))

profiles = [profile_off, profile_class, profile_rest, profile_elec]
titles = ['Office occupancy', 'Class occupancy', 'Restaurant occupancy', 'Electricity profile']
for i, profile in enumerate(profiles):
    #axs[i].plot(profile[72:96])
    axs[i].bar(range(0, 24), profile[72:96])
    axs[i].set_xticks(np.arange(1, 24, 2))
    axs[i].set_xticklabels(np.arange(1, 24, 2))
    axs[i].set_title(titles[i])
fig.tight_layout()
plt.show()
```

The occupancy profile is assumed to be the same across all buildings. Following the SIA audit, the heat generated by people depends on the type of room considered. To every building one assigns a share of the total are to a dedicated type of room, named $A_{share,i}$. Using that, it is easy to derive a specific heat gain by the people determined by the equation @eq-people-heat-gain:
$$
q_\text{people}(t) = \sum_i A_\text{share,i} \cdot hg_\text{share,i} \cdot p_i(t), i \in \mathrm{[Office, Restaurant, Classroom, Others]} 
$${#eq-people-heat-gain}

where:

- $A_\text{share,i}$: the area share of a room i
- $hg_\text{share,i}$: the heat flux generated in a room i
- $p_i(t)$: the occupancy profile of people in a room i

Notice that this is a constant value since the profiles $p_i(t)$ are supposed to be the same for all buildings. Now, $q_\text{el}(t)$ and $q_\text{people}(t)$ are characterized.

## Estimation of $k_\text{th}$ and $k_\text{sun}$ {#subsec:estimation-of-k-th-and-k-sun}

The two remaining unknowns to be determined are the thermal and solar constants, $k_\text{th} [\frac{W}{K \cdot m^2}]$ and $k_\text{sun}$. Since the data available is the heating consumption $Q_\text{th,year}^+$, the equation @eq-building-balance has to be restricted accordingly, constructing a first equation:
$$
Q_\text{th,year}= \sum Q_\text{th}^+(t)
$$ {#eq-heat-demand}

In short, the annual heating demand is the sum of all hourly demands. The hourly demands are heating demands only if $Q_\text{th} > 0$.

The equation @eq-building-balance alone is not sufficient to solve the problem, but assuming a specific operating condition, it is possible to construct another one, i.e. when the heat demand $Q_\text{th}$ is zero. When the system is in this "no-load" condition, it means the temperature gradient is perfectly balanced by the people heat gains, the sun irradiance, and the electricity heat gains. The switch-off condition is assumed to be valid when sufficiently close to the cutoff temperature $T_\text{th}$. Taking an average of all of these values when the heating is turned off allows stating a second equation @eq-switch-off:
$$
0 = A_\text{th} \cdot (k_\text{th} \cdot (T_\text{int} - T_\text{ext}(t)) - k_\text{sun} \cdot i_\text{mean}(t) - q_\text{people,mean}(t) - f_\text{el} \cdot q_\text{el,mean}(t)) 
$${#eq-switch-off}

Combining equations @eq-heat-demand and @eq-switch-off allows constructing a system of two equations and two unknowns. However, since a sum is involved in equation @eq-heat-demand, the system is nonlinear. The solutions will thus be estimated through numerical methods, e.g. a 2D Newton-Raphson algorithm.


<!--Generate k_th and k_th -->
```{python, echo=F, results='hide', label='generate kth and ksun'}
#Run the NR algorithm to produce the k_th and k_sun for every building
thermal_properties  = pd.DataFrame(columns=['FloorArea', 'specElec', 'k_th', 'k_sun', 'specQ_people'])
NR_info             = pd.DataFrame(columns=['error_k_th','error_k_sun','number_iteration'])
Q_th = pd.DataFrame(columns=buildings['Name']) 
T_ext = weather.Temp + 273 # K
irr = weather.Irr # W/m2

q_people = fct1.people_gains(profile_class, profile_rest, profile_off)

for building_id in buildings['Name']:
    #Estimate k_th and k_sun for each building
    q_elec = fct1.elec_gains(building_id, buildings, profile_elec)
    [k_th, k_sun, number_iteration, error1, error2, A_th, specQ_people, specElec, heating_indicator] = fct1.solving_NR(building_id, buildings, weather, q_elec, q_people, profile_elec)
    thermal_properties.loc[building_id] = pd.Series({'FloorArea': A_th, 'specElec': specElec/1000, 'k_th': k_th/1000, 'k_sun': k_sun,'specQ_people': specQ_people/1000})
    NR_info.loc[building_id] = pd.Series({'error_k_th': error1,'error_k_sun':error2,'number_iteration':number_iteration})


    #Compute Q_th for each hour
    Q_th[building_id] = A_th*(k_th*(T_int-T_ext) - q_people - k_sun*irr - q_elec*f_el)/1000 # Wh--> kWh
    Q_th[heating_indicator==0] = 0 # Set Q_th to be only heat demand

print(NR_info)

PATH = os.path.dirname(os.getcwd()) # the path to codes_01_energy_demand.py
thermal_properties.to_csv(os.path.join(PATH,"report-group-3","codes_01_energy_demand", "thermal_properties.csv"),index=False)
```


```{r table-widget, echo=F, eval=T, fig.cap= 'Thermal properties of the buildings'}
#| label: fig-thermalProp

thermal_properties <- read.csv("codes_01_energy_demand/thermal_properties.csv")

library(DT)

col_names <- c("FloorArea [m²]","specElec [kW/m²]", "k_th [kW/m²]","k_sun [-]","specQ_people [kW/m²]")

datatable(
  round(thermal_properties, digits=5),
  options = list(
    pageLength = 5,
    scrollX = TRUE
  ),
  colnames = col_names
)
```

<details>
<summary> Convergence info </summary>

The maximum number of iteration of the NR algorithm is set to 1000 by default and its tolerance to 1e-6 by default. The error criterion is stated on both x and y variation and is based on the absolute distance between iterations. The technical algorithm outputs are stated hereafter.

```{r table-widget, echo=F, eval=T, fig.cap= 'NR convergence info'}
#| label: NR_convergence_info

python_NR_info <- py$NR_info

r_NR_info <- as.data.frame(python_NR_info)

library(DT)

col_names <- c("Error on kth","Error on ksun", "Number of iteration")

datatable(
  round(r_NR_info, digits=10),
  options = list(
    pageLength = 5,
    scrollX = TRUE
  ),
  colnames=col_names
)
```

</details>

## Impact of renovation and indoor temperature {#subsec:ksun}

Having determined $k_\text{th}$ and $k_\text{sun}$, a sensitivity analysis can be performed to study their impact on the energy consumption of the buildings. On one hand, $k_\text{th}$, which represents the leakage losses, should be decreased and on the other hand, $k_\text{sun}$, which characterizes the solar gains, needs to be increased. The solar gains can be increased by changing the absorptivity of the building, i.e. either by replacing the building’s coating or using a different paint on the exterior façade. As for the constraint on $k_\text{th}$, it is the sum of the ventilation and the building losses : $k_\text{th}=U_\text{env}+\dot{m_\text{air}}Cp_\text{air}$. The air renewal rate meeting requirements to avoid high $CO_\text{2}$ concentration, it is difficult to change this value to decrease the leakage losses. Therefore, one must decrease the value of $U_\text{env}$. To do so, the building isolation can be improved by changing the thickness or the material of the walls and windows. However, this is linked to high renovation cost and to long labor duration compared to the possible gains by changing $k_\text{sun}$. Increasing $k_\text{sun}$ by 25, 50 and 75 $\%$, one can influence the evolution of the heat demand:

```{r ksun-var, out.width='100%', fig.align='center', fig.cap='Variation of Qheating with different ksun', echo=F, fig.show='hold'}
#| label: ksun-var
knitr::include_graphics('Figures/k_sun_var.png')
```

The figure shows, that during seasons when the irradiation is low (winter and fall) and when the heating demand is at its lowest (summer), the variation of $k_\text{sun}$ does not change significantly the value of the heating demand. Nevertheless, during spring where the impact of $k_\text{sun}$ on the heating demand is the highest, one can see that the variation of $Q_\text{heating}$ is the greatest. Zooming on the picture, one notices that the yellow points representing the heating demand of the highest increase in $k_\text{sun}$ are the lowest.

## Clustering {#subsec:clustering}

Now that the buildings are physically characterized, it is possible to solve the energy demand equation @eq-building-balance. However, for a yearly optimization of this equation, this would mean optimizing for 8760 different demands. Reducing the data might help run a more efficient optimization. Clustering helps defining typical time periods that are representative enough of the heat loads. To do so, clustering of the weather data is performed and will be used to solve a reduced number of energy balance equations. 

### Weather Data preprocessing

Before starting the clustering, the temperature and irradiance data are split in three groups:

- Type A: timesteps where the buildings are used (Monday to Friday 7am to 9pm) and the external
temperature is below the cut off temperature of 16 °C.
- Type B: the exact opposite of type A leaving the timesteps when the buildings are not used (night,
weekend) and the external temperature is greater than 16 °C.
- Type O: the coldest hour of the year as extreme timestep.


```{python, echo=F, eval=T}
#| label: weather cluster plotting

#Add 'Type' column
weather = fct1.preprocess_data(weather, profile_elec)

# Create the initial figure
fig_weather = px.scatter(weather, x=weather.index, y='Temp', color='Type', title='Weather data - Temperature (processed)',
                         labels={'Temp': 'Temperature [°C]', 'Hours': 'Hour'})

# Use a context manager to delay the display
with fig_weather.batch_update():

    fig_weather.update_xaxes(title='Hour')

    # Add horizontal line at 16°C
    fig_weather.add_shape(type='line', x0=0, x1=len(weather), y0=16, y1=16, line=dict(color='red'))

    # Write "16°C" next to the line
    fig_weather.add_annotation(text='16°C', xref='paper', yref='y', x=0, y=17, showarrow=False, font=dict(color='red'))

    # Show the legend
    fig_weather.update_layout(legend_title_text='Type')

fig_weather = px.scatter(weather, x=weather.index, y='Irr', color='Type', title='Weather data - Irradiation (processed)',
                         labels={'Irr': 'Irradiation [W/m2]', 'Hours': 'Hour'})
                         
fig_weather.show()
```

### Method selection

Clustering via Machine Learning is now widely spread and lot of tools allow for easy implementation. Using Sci-Kit, the weather data are clustered using unsepervised algorithms. Kmeans, Spectral clustering and agglomerate clustering are probed. A common metric used to asses of the relevancy of such clustering is the Sum of Squared Errore (SSE). The visualisation of the clustering for $k=10$ clusters is shown in the figure (@fig-clusteringComp). The SSE is summarized in the table (@tbl-clusteringSSE).

_Note:_ the data has been normalized to perform the clustering to improve perfomances, and reversed back to be plotted.

```{python, echo = F, eval=T}
#| label: fig-clusteringComp
#| fig-cap: Different clustering method results

n_clusters = 10
kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init='auto')
spectral = SpectralClustering(assign_labels='discretize', n_clusters=n_clusters, random_state=0)
agglo = AgglomerativeClustering(n_clusters=n_clusters)

weather_clustering = WeatherClustering(weather, n_clusters, profile_elec)
weather_clustering.preprocess_data()

fig, axs = plt.subplots(1, 3, figsize=(15, 5))

titles = ['Spectral Clustering','Agglomerative Clustering','KMeans Clustering']

fig.suptitle(f'Clustering comparison, {n_clusters} clusters')

for i, method in enumerate([spectral, agglo, kmeans]):
    weather_clustering.clustering(method)
    weather_clustering.plot_clusters(axs[i])
    axs[i].set_title(titles[i])

plt.show()
```

|     | Spectral | Agglo | Kmeans |
|-----|----------|-------|--------|
| SSE | 241      |  236  |  196   |
: Clustering SSE {#tbl-clusteringSSE}


The most promising method is thus the Kmeans algorithm, which will be selected to define typical operating conditions.

### Hyperparameter $k$ selection 

Choosing to work with Kmeans clustering still leaves room to fiddle with the number of cluster to choose. A common way to choose this parameter is the use of the "Elbow method", which allows to select the right number of clusters doing a compromise between the precision and the number of clusters. Inspection of (@fig-elbowMethod) allows to think that $k=6$ is a relatively good trade off.

```{python, echo = F, eval=T, label = 'fig-elbowMethod', fig.cap='Elbow method'}
#| label: fig-elbowMethod
#| 
fct1.elbow_method(weather_clustering.data,15)
```

For the sake of completion, we mention that a Silhouette test has also been performed and returned an optimal $k=4$. However, the overall scores were all low, due to the metric's nature: since all the data points are lying in a region, data structure discovery is unlikely and clustering acts more as a way to split the space evenly. And since Silhouette score penalize intercluster closeness, all scores drops since no clear clusters are underyling the distribution. In the end, the error on the variable of interest, $Q_{th}$, is almost divided by two from $k=4$ to $k=6$, and is thus still a valid choice.

### Clustering results
The result of the clustering are shown below. 

```{python, echo=F, eval=T, results = 'hide'}
#| label: perform clustering

weather, cluster = fct1.clusteringCorentin(weather,n_clusters=6)

Q_th_cluster = pd.DataFrame(columns=buildings.Name)
# Extract thermal_properties of buildings
A_th            = thermal_properties['FloorArea']    # m^2
k_th            = thermal_properties['k_th']         # kW/m^2 K
k_sun           = thermal_properties['k_sun']        # -
specQ_people    = thermal_properties['specQ_people'] # kW/m^2
specElec        = thermal_properties['specElec']     # kW/m^2

T_cluster       = cluster['Temp'] + 273              # C° --> K
irr_cluster     = cluster['Irr']/1000                # W/m^2 --> kW/m^2 

# Recompute thermal load for each cluster using cluster centers
for building_id in buildings['Name']:
    Q_th_cluster[building_id] = A_th[building_id]*(k_th[building_id]*(T_int-T_cluster) - k_sun[building_id]*irr_cluster - specQ_people[building_id] - specElec[building_id]*f_el) # [kWh]

Q_th_cluster[Q_th_cluster < 0]  = 0                                                         # Set negative values to 0
Q_th_cluster                    = Q_th_cluster[buildings['Name'].loc[buildings.Year == 1]]  # Select only medium temp buildings
Q_th_cluster                    = Q_th_cluster.sum(axis=1)                                  # Get total hourly demand per cluster
Q_th_cluster                    = Q_th_cluster*cluster['Hours']                             # Get annual demand

cluster['Q_th'] = Q_th_cluster

cluster.to_csv(os.path.join(PATH,"report-group-3","codes_01_energy_demand", "clusters_data.csv"), index=False)

```

```{python, echo=F, eval = T}
#| label: plot clustering 
# Scatter plot for weather data type A
fig = px.scatter(weather.loc[weather['Type']=='A'], x='Temp', y='Irr', color="Cluster", 
                 title='Weather data type A', labels={'Temp': 'Temperature [°C]', 'Irr': 'Irradiation [W/m2]'})
cluster_trace = go.Scatter(
    x=cluster.iloc[:, 0],
    y=cluster.iloc[:, 1],
    mode='markers',
    marker=dict(color='red', size=20, opacity=0.8),
    name='Cluster Centroids'
)
fig.add_trace(cluster_trace)

cluster.rename(columns={
    'Temp': 'Temperature [°C]',
    'Irr': 'Irradiance [W/m²]',
    'Hours': 'Operating time [h]',
    'Q_th' : 'Heat load [kWh/year]'
}, inplace=True)
html_table = cluster.round(2).to_html()
title_html = '<h4 style="text-align:center;">Cluster Centroids</h4>'
final_html = title_html + html_table
HTML(final_html)
```

```{python, echo=F, eval = T}
#| label: compute clustering error
clustering_error = (buildings['Heat'].loc[buildings.Year == 1].sum()-Q_th_cluster.sum())/buildings['Heat'].loc[buildings.Year == 1].sum()*100
```

Computing the sum of the type 1 heat demands and the sum of the cluster heat loads allows to compute the relative error we've made on the total heat demand reconstruction, which is `r reticulate::py_eval("f'{clustering_error:.4}'")`%.