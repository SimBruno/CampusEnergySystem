---
title: "Energy demand of the EPFL campus"
editor: visual
---


```{r, echo=F, results='hide',label='activate venv'}
#path <- file.path('./venv/bin/python')
library(reticulate)
#use_python(path)
use_virtualenv('./venv', required=FALSE)
```

```{python package, echo=F, results='hide', label='load data'}
import codes_01_energy_demand.NR_functions as fct1
import numpy as np; from numpy import matlib
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering
import os

```

```{python, echo=F, results='hide', label='load parameters'}
weather, buildings = fct1.load_data_weather_buildings()
h = 8760  # Hours in a year
T_th = 273 + 16 # Cut off temperature [K]
cp_air = 1152 # Air specific heat capacity [J/(m3.K)] 
T_int = 273 + 21 # Set point temperature [K]
air_new = 2.5 # Air renewal [m3/(m2.h)]
Vent = 0 # [...]
f_el = 0.8 # Share of electricity demand which is converted to heat appliances
```

## Buildings Energy Balance {#subsec:building-energy-balance}

This first section aims to first estimate the energy demand of the EPFL campus. For this purpose, the annual energy consumption of the buildings are given, in the following format:

```{python, echo=F, results='show', label='df preview'}
buildings.head(2)
```

Where $Ground$ is the building surface area in $[m^2]$, $Heat$ is the building annual heating consumption in $[kWh]$, $Elec$ is the building annual electricity consumption in $[kWh]$ and $Year$ is the building group identifier.

Furthermore, the hourly weather data during that year are also available, i.e external temperature and solar irradiation. Thanks to these data, it is possible to characterize the physical properties of the buildings. Performing an energy balance on a building yields the following equation:
$$
Q_\text{th} = A_\text{th} \cdot (k_\text{th} \cdot (T_\text{int} - T_\text{ext}(t)) - k_\text{sun} \cdot i(t) - q_\text{people}(t) - f_\text{el} \cdot q_\text{el}(t))
$${#eq-building-balance}

where:

- $A_\text{th}$: reference heated surface (m^2)
- $k_\text{th}$: thermal losses and ventilation coefficient in (W/m^2/K)
- $T_\text{int}$: internal set point temperature equal to 21°C
- $T_\text{ext}(t)$: external ambient temperature (°C)
- $k_\text{sun}$: solar radiation coefficient [-]
- $i(t)$: solar global radiation per area (W/m^2), given in the project appendice
- $q_\text{people}(t)$: heat gain due to the presence of people per unit area (W/m^2)
- $f_\text{el}$: share of electricity demand converted to heat appliances [-]
- $q_\text{el}(t)$: Electricity demand (W/m^2)
- $Q_\text{th}(t)$: Heat load (heating demand when positive, cooling when negative)

The unknowns are $q_\text{people}(t)$, $q_\text{el}(t)$, $k_\text{th}$, and $k_\text{sun}$. In a first step, using the occupancy profile of the buildings, the heat generation from people and the electricity demand will be derived, using the known annual demand.

## Hourly Profiles {#subsec:hourly-profiles}

The electricity profile demand is assumed to be constant when on, and is on during weekdays from 7 AM to 9 PM. The values of the constant profile are simply the specific electricity consumption of the building divided by the number of operating hours.


<!-- Generate elec profile -->
```{python, echo=F, results='show', label='generate profiles'}
profile_off, profile_class, profile_rest, profile_elec = fct1.occupancy_profile()
```


```{python, eval =F, echo=F, results='show', label='plot profiles'}
fig, axs = plt.subplots(1, 4, figsize=(14, 3))
axs[0].plot(profile_off[72:96])
axs[0].set_title('Office occupancy')
axs[1].plot(profile_class[72:96])
axs[1].set_title('Class occupancy')
axs[2].plot(profile_rest[72:96])
axs[2].set_title('Restaurant occupancy')
axs[3].plot(profile_elec[72:96])
axs[3].set_title('Electricity profile')
fig.tight_layout()
plt.show()
```

The occupancy profile is assumed to be the same across all buildings. Following the SIA audit, the heat generated by people depends on the type of rooms considered. A typical public building has a typical share of its total area dedicated to those types of rooms. Using that, it is easy to derive a specific heat gain by the people determined by the equation @eq-people-heat-gain:
$$
q_\text{people}(t) = \sum_i A_\text{share,i} \cdot hg_\text{share,i} \cdot p_i(t), i \in \mathrm{[Office, Restaurant, Classroom, Others]} 
$${#eq-people-heat-gain}

where:

- $A_\text{share,i}$: the area share of a room i
- $hg_\text{share,i}$: the heat flux generated in a room i
- $p_i(t)$: the occupancy profile of people in a room i

Notice that this is a constant value since the profiles $p_i(t)$ are supposed to be the same for all buildings. Now, $q_\text{el}(t)$ and $q_\text{people}(t)$ are characterized.

## Estimation of $k_\text{th}$ and $k_\text{sun}$ {#subsec:estimation-of-k-th-and-k-sun}

The two remaining unknowns to be determined are the thermal and solar constants, $k_\text{th}$ and $k_\text{sun}$. Since the data available is the heating consumption $Q_\text{th,year}^+$, the equation @eq-building-balance has to be restricted accordingly, constructing a first equation:
$$
Q_\text{th,year}= \sum Q_\text{th}^+(t)
$$ {#eq-heat-demand}

In short, the annual heating demand is the sum of all hourly demands. The hourly demands are heating demands only if $Q_\text{th} > 0$.

The equation @eq-building-balance alone is not sufficient to solve the problem, but assuming a specific operating condition, it is possible to construct another one, i.e. when the heat demand $Q_\text{th}$ is zero. When the system is in this "no-load" condition, it means the temperature gradient is perfectly balanced by the people heat gains, the sun irradiance, and the electricity heat gains. The switch-off condition is assumed to be valid when sufficiently close to the cutoff temperature $T_\text{th}$. Taking an average of all of these values when the heating is off allows stating a second equation @eq-switch-off:
$$
0 = A_\text{th} \cdot (k_\text{th} \cdot (T_\text{int} - T_\text{ext}(t)) - k_\text{sun} \cdot i_\text{mean}(t) - q_\text{people,mean}(t) - f_\text{el} \cdot q_\text{el,mean}(t)) 
$${#eq-switch-off}

Combining equations @eq-heat-demand and @eq-switch-off allows constructing a system of two equations and two unknowns. However, since a sum is involved in equation @eq-heat-demand, the system is nonlinear. The solutions will thus be estimated through numerical methods, e.g. a 2D Newton-Raphson algorithm.


<!--Generate k_th and k_th -->
```{python, echo=F, results='show', label='generate kth and ksun'}
#Run the NR algorithm to produce the k_th and k_sun for every building
solution  = pd.DataFrame(columns=['FloorArea', 'specElec', 'k_th', 'k_sun', 'specQ_people'])
Q_th = pd.DataFrame(columns=buildings['Name']) 
T_ext = weather.Temp + 273 # K
irr = weather.Irr # W/m2
for building_id in buildings['Name']:
        q_people = fct1.people_gains(profile_class, profile_rest, profile_off)
        q_elec = fct1.elec_gains(building_id, buildings, profile_elec)
        [k_th, k_sun, number_iteration, error1,error2, A_th, specQ_people, q_elec_mean] = fct1.solving_NR(building_id, buildings, weather,q_elec,q_people,profile_elec)
        solution.loc[building_id] = pd.Series({'FloorArea': A_th, 'specElec': q_elec_mean, 'k_th': k_th, 'k_sun': k_sun,'specQ_people': specQ_people})
        # Recompute hourly energy demands
        Q_th[building_id] = A_th*(k_th*(T_int-T_ext) - q_people - k_sun*irr - q_elec*f_el)
print(solution.head(3))
```

## Clustering {#subsec:clustering}

Now that the buildings are physically characterized, it is possible to solve the energy demand equation @eq-building-balance. However, for a yearly optimization of this equation, this would mean optimizing for 8760 different demands. Reducing the data might help run a more efficient optimization. Clustering helps defining typical time periods that are representative enough of the heat loads. To do so, clustering of the weather data is performed and will be used to solve a reduced energy balance equation. 


```{python, echo=F, eval=F, results='show', label='kmeans clustering 2'}

n_clusters = 5

algos = {
    'kmeans': KMeans(n_clusters=n_clusters, random_state=0, n_init = 'auto'),
    'spectral': SpectralClustering(assign_labels='discretize', n_clusters=n_clusters, random_state=0),
    'agglo': AgglomerativeClustering(n_clusters=n_clusters)
}

for algo_name, algo_instance in algos.items():
    algo_name = fct1.WeatherClustering(weather, n_clusters, profile_elec)
    algo_name.preprocess_data()
    algo_name.clustering(algo_instance)

print(kmeans.sse)
```

### Method selection

Clustering via Machine Learning is now widely spread and lot of tools allow for easy implementation. Using Sci-Kit, the weather data are clustered using unsepervised algorithm. Kmeans, Spectral clustering and agglomerate clustering are probed. A common metric used to asses of the relevancy of such clustering is the Sum of Squared Errore (SSE). The visualisation of the clustering for $k=10$ clusters is shown in the figure (@fig-clusteringComp). The SSE is summarized in the table (@tbl-clusteringSSE).

_Note:_ the data has been normalized to perform the clustering, and reversed to plot

![Clustering comparison](Figures/clusteringComparison.PNG){#fig-clusteringComp fig-align="center" width=100%}

|     | Spectral | Kmeans | Agglo |
|-----|----------|--------|-------|
| SSE | 241      | 196    | 236   |

The most promising method is thus the Kmeans algorithm, which will be selected to define typical operating conditions.

### Hyperparameter $k$ selection 

Choosing to work with Kmeans clustering still leave room to fiddle with the number of cluster to choose. A common way to choose this parameter is the use of the "Elbow method", which visually indicates where the errors starts to decrease less meaningfully as the number of cluster increases. Inspection of (@fig-clusteringElbow) allows to think that $k=6$ is a relatively good trade off.



![Clustering comparison](Figures/clusteringElbow.PNG){#fig-clusteringElbow fig-align="center" width=100%}


### Clustering results

Assigning every timestamps to its cluster allows to decompose the heat demand as following: 

|Type     |   Cluster  | $Q_\text{th}$ (kw/h)|
|---------|------------|---------------|
| A       | 0          |               |
| A       | 1          |               |
| A       | 2          |               |
| A       | 3          |               |
| A       | 4          |               |
| A       | 5          |               |
| B       | 6          |               |
| Extreme | 7          |               |



Here you report what you have done and found concerning part 1. It includes the parametric estimations of the electricity demand, the heat gains from the people, the Kth and Ksun values using Newton_Raphson and the typical period clustering. All .qmd files present in the main folder are read while rendering the book. The four folders called **codes** are here to make your calculations. The files contained in these folders are not read while rendering the book. **We advice you to work and develop your models in the subfolders only**. Then you will use the .qmd in the main folder to report the models and data generated in the sub-folders. 

**Important note: when you are working on your functions and models, open VScode at the level of the subfolders to avoid path issues!**

## Objective

The main objective of this part of the project is to **analyze the energy demands of the EPFL campus**, with a focus on the heating demands and design characteristics of the various buildings on-site. Understanding the thermal design of the buildings (wall properties, heat gains, thermal losses) is important for a proper control of the amount of energy required to ensure thermal comfort throughout the year. To this end you are asked to: 

 1. calculate the thermal gains from people and electronic appliances, based on the occupancy profiles of the buildings 
 2. estimate the thermal properties of the buildings based on the annual heating demand 
 3. Identify the most frequent and extreme working conditions (typical periods)
 4. Derive the hourly heating demand over the whole year for the buildings

In the reminaing of the project, you will use the results obtained at the end of this part.

## Code Guidelines

For this **Part 1** you have at your disposition:

 - Two .csv files *Buildings.csv* and *Weather.csv* containing the data to process
 - A python file *NR_functions.py* where you will develop your functions to solve part 1
 - A **book** in **Quarto** *01.00-Energy_demand.qmd* (the file where you are now) where you will call your functions and data to report the results

Most of the development will take place in the python file *NR_functions.py*. Once your functions are running well, you will use to this .qmd file for the reporting and call your functions to generate and plot results.

In *NR_functions.py*, the data are imported using [Pandas](http://pandas.pydata.org) library, and we suggest you to make your calculations using the [Numpy](http://www.numpy.org) library. In addition to this, you are welcome to use any other libraries or toolboxes for the project. Regarding the plots, we advise you to use either [Matplotlib](https://matplotlib.org/), [Seaborn](https://seaborn.pydata.org/) or [Plotly Python](https://plotly.com/python/). **Even though we propose a certain structure for the function, you are totally free to restructure them the way you prefer. It only aims to help you start with the project by providing skeleton functions. If you find it more convenient to do it very differently, you are welcome to do so.**

Before starting, check that your venv folder has been created the first time you have rendered the index.qmd. 


## Reporting
In the following, we provide you some piece of codes to integrate your functions and data in the report. 
In the first chunk, you specify the path to your venv folder. 



If some python packages are missing, you can install them yourself in the venv. Below is an example. Don't forget to comment the chunk once the package has been installed in your venv (echo=F). Note that here we are using an R chunk to do this. You could as well use the terminal.
```{r, eval=F}
py_install("seaborn")
```


Load the data:


Overview of the Buildings dataframe

```{python table plot, echo=F}
import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=list(buildings.columns),
                fill_color='lightskyblue',
                line_color='darkslategray',
                align='center'),
    cells=dict(values=[buildings[col] for col in buildings],
               fill_color='white',
               line_color='darkslategray',
               align='center'))
])
fig.update_layout(width=800, height=700)

```


## TASK 1 - Calculation of the internal heat gains (people & appliances)

Using python chunks and functions in NR_functions.py, calculate the heat gains from people and appliances.

Then find the values of kth and ksun for every building. Finally, store all your results in a new .csv file to use them later. 

### Internal gains - People

```{python, echo=T, results='hide'}
# Generate the yearly occupancy profile of the buildings
occ_profile = fct1.occupancy_profile()
```



### Internal gains - Electronic appliances


## TASK 2 - Calculation of the building thermal properties (k<sub>th</sub> and k<sub>sun</sub>)

Parameters for Newton-Raphson iterations


Mean values computation and proper initialisation

## TASK 4 - Clustering

The clustering should be performed on weather data, in our case external temperature and irradiation. Remind that it is highly recommended to normalize the data before clustering.

It is required to apply at least two clustering methods and to compare the quality of the generated typical periods. It is your choice to select the preferred methodology to reduce the data. Give some visual representations of your clustering results.

Optional: To conclude this first part, you can plot the hourly heat demand of the campus based on the internal heat gains, k_sun, k_th and your typical periods.

