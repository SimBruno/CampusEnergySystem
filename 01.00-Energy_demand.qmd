---
title: "Energy demand of the EPFL campus"
editor: visual
---


```{r, echo=F, results='hide',label='activate venv'}
#path <- file.path('./venv/bin/python')
library(reticulate)
#use_python(path)
use_virtualenv('./venv', required=FALSE)
```

```{python, echo=F, results='hide', label='load data'}
import matplotlib
matplotlib.use('Agg')
import codes_01_energy_demand.NR_functions as fct1
from codes_01_energy_demand.NR_functions import WeatherClustering
import numpy as np; from numpy import matlib
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering
import os
import plotly.express as px
import plotly.graph_objects as go
from IPython.display import display, HTML
```

```{python, echo=F, results='hide', label='load parameters'}
weather, buildings = fct1.load_data_weather_buildings()
h = 8760  # Hours in a year
T_th = 273 + 16 # Cut off temperature [K]
cp_air = 1152 # Air specific heat capacity [J/(m3.K)] 
T_int = 273 + 21 # Set point temperature [K]
air_new = 2.5 # Air renewal [m3/(m2.h)]
Vent = 0 # [...]
f_el = 0.8 # Share of electricity demand which is converted to heat appliances
```

## Buildings Energy Balance {#subsec:building-energy-balance}

This first section aims to estimate the energy demand of the EPFL campus. For this purpose, the annual energy consumption of the buildings is given, in the following format:

```{python, echo=F, eval=F, results='show'}
#| label: df preview
buildings.head(2)
```

```{r , echo=F, eval=T}
#| label: fig-buildings
#| fig-cap: Buildings data

buildings <- read.csv("codes_01_energy_demand/Buildings.csv")

library(DT)

datatable(buildings, options = list(pageLength = 5,scrollX = TRUE)            
)
```


Where $Ground$ is the building surface area in $[m^2]$, $Heat$ is the building annual heating consumption in $[kWh]$, $Elec$ is the building annual electricity consumption in $[kWh]$ and $Year$ is the building group identifier.

Furthermore, the hourly weather data during that year are also available, i.e external temperature and solar irradiation. Thanks to these data, it is possible to characterize the physical properties of the buildings. Performing an energy balance on a building yields the following equation:
$$
Q_\text{th} = A_\text{th} \cdot (k_\text{th} \cdot (T_\text{int} - T_\text{ext}(t)) - k_\text{sun} \cdot i(t) - q_\text{people}(t) - f_\text{el} \cdot q_\text{el}(t))
$${#eq-building-balance}

where:

- $A_\text{th}$: reference heated surface [m<sup>2</sup>]
- $k_\text{th}$: thermal losses and ventilation coefficient in [W/m<sup>2</sup>/K]
- $T_\text{int}$: internal set point temperature equal to 21°C
- $T_\text{ext}(t)$: external ambient temperature [°C]
- $k_\text{sun}$: solar radiation coefficient [-]
- $i(t)$: solar global radiation per area [W/m<sup>2</sup>], given in the project appendice
- $q_\text{people}(t)$: heat gain due to the presence of people per unit area [W/m<sup>2</sup>]
- $f_\text{el}$: share of electricity demand converted to heat appliances [-]
- $q_\text{el}(t)$: Electricity demand [W/m<sup>2</sup>]
- $Q_\text{th}(t)$: Heat load (heating demand when positive, cooling when negative) [W]

The unknowns are $q_\text{people}(t)$, $q_\text{el}(t)$, $k_\text{th}$, and $k_\text{sun}$. To begin with, with the occupancy profile of the buildings, the heat generation from people and the electricity demand will be derived, using the known annual demand.

## Hourly Profiles {#subsec:hourly-profiles}

The electricity profile demand is assumed to be constant when turned on. Electricity is used on weekdays from 7 AM to 9 PM. The values of the uniform electrictiy profile are calculated by dividing the specific electricity consumption of the buildings by the number of operating hours, i.e. 3654 hours per year.


<!-- Generate elec profile -->
```{python, echo=F, results='show'}
#| label: generate profiles
profile_off, profile_class, profile_rest, profile_elec = fct1.occupancy_profile()
```


```{python, eval =T, echo=F, results='show', label='plot profiles', fig.cap='Occupancy profiles'}
fig, axs = plt.subplots(1, 4, figsize=(14, 3))

profiles = [profile_off, profile_class, profile_rest, profile_elec]
titles = ['Office occupancy', 'Class occupancy', 'Restaurant occupancy', 'Electricity profile']
for i, profile in enumerate(profiles):
    #axs[i].plot(profile[72:96])
    axs[i].bar(range(0, 24), profile[72:96])
    axs[i].set_xticks(np.arange(1, 24, 2))
    axs[i].set_xticklabels(np.arange(1, 24, 2))
    axs[i].set_title(titles[i])
fig.tight_layout()
plt.show()
```

The occupancy profile is assumed to be the same across all buildings. Following the SIA audit, the heat generated by people depends on the type of room considered. To every building one assigns a share of the total are to a dedicated type of room, named $A_{share,i}$. Using that, it is easy to derive a specific heat gain by the people determined by the equation @eq-people-heat-gain:
$$
q_\text{people}(t) = \sum_i A_\text{share,i} \cdot hg_\text{share,i} \cdot p_i(t), i \in \mathrm{[Office, Restaurant, Classroom, Others]} 
$${#eq-people-heat-gain}

where:

- $A_\text{share,i}$: the area share of a room i
- $hg_\text{share,i}$: the heat flux generated in a room i
- $p_i(t)$: the occupancy profile of people in a room i

Notice that this is a constant value since the profiles $p_i(t)$ are supposed to be the same for all buildings. Now, $q_\text{el}(t)$ and $q_\text{people}(t)$ are characterized.

## Estimation of $k_\text{th}$ and $k_\text{sun}$ {#subsec:estimation-of-k-th-and-k-sun}

The two remaining unknowns to be determined are the thermal and solar constants, $k_\text{th} [\frac{W}{K \cdot m^2}]$ and $k_\text{sun}$. Since the data available is the heating consumption $Q_\text{th,year}^+$, the equation @eq-building-balance has to be restricted accordingly, constructing a first equation:
$$
Q_\text{th,year}= \sum Q_\text{th}^+(t)
$$ {#eq-heat-demand}

In short, the annual heating demand is the sum of all hourly demands. The hourly demands are heating demands only if $Q_\text{th} > 0$.

The equation @eq-building-balance alone is not sufficient to solve the problem, but assuming a specific operating condition, it is possible to construct another one, i.e. when the heat demand $Q_\text{th}$ is zero. When the system is in this "no-load" condition, it means the temperature gradient is perfectly balanced by the people heat gains, the sun irradiance, and the electricity heat gains. The switch-off condition is assumed to be valid when sufficiently close to the cutoff temperature $T_\text{th}$. Taking an average of all of these values when the heating is turned off allows stating a second equation @eq-switch-off:
$$
0 = A_\text{th} \cdot (k_\text{th} \cdot (T_\text{int} - T_\text{ext}(t)) - k_\text{sun} \cdot i_\text{mean}(t) - q_\text{people,mean}(t) - f_\text{el} \cdot q_\text{el,mean}(t)) 
$${#eq-switch-off}

Combining equations @eq-heat-demand and @eq-switch-off allows constructing a system of two equations and two unknowns. However, since a sum is involved in equation @eq-heat-demand, the system is nonlinear. The solutions will thus be estimated through numerical methods, e.g. a 2D Newton-Raphson algorithm.


<!--Generate k_th and k_th -->
```{python, echo=F, results='show', label='generate kth and ksun'}
#Run the NR algorithm to produce the k_th and k_sun for every building
thermal_properties  = pd.DataFrame(columns=['FloorArea', 'specElec', 'k_th', 'k_sun', 'specQ_people'])
Q_th = pd.DataFrame(columns=buildings['Name']) 
T_ext = weather.Temp + 273 # K
irr = weather.Irr # W/m2

Q_extreme = []
T_extreme = []
irr_extreme = []

q_people = fct1.people_gains(profile_class, profile_rest, profile_off)

for building_id in buildings['Name']:
    #Estimate k_th and k_sun for each building
    # q_people = fct1.people_gains(building_id, profile_class, profile_rest, profile_off)
    q_elec = fct1.elec_gains(building_id, buildings, profile_elec)
    [k_th, k_sun, number_iteration, error1, error2, A_th, specQ_people, q_elec_mean, heating_indicator] = fct1.solving_NR(building_id, buildings, weather, q_elec, q_people, profile_elec)
    thermal_properties.loc[building_id] = pd.Series({'FloorArea': A_th, 'specElec': q_elec_mean/1000, 'k_th': k_th/1000, 'k_sun': k_sun,'specQ_people': specQ_people/1000})
    #Compute Q_th for each hour
    Q_th[building_id] = A_th*(k_th*(T_int-T_ext) - q_people - k_sun*irr - q_elec*f_el)/1000 # Wh--> kWh

Q_th[heating_indicator==0] = 0 # Set Q_th to be only heat demand

# Q_extreme.append(A_th*(k_th*(T_int-(273-9.2)) - specQ_people - q_elec_mean*f_el)/1000)

#Q_th = Q_th[heating_indicator]/1000 #kWh conversion
# save the table 
PATH = os.path.dirname(os.getcwd()) # the path to codes_01_energy_demand.py
thermal_properties.to_csv(os.path.join(PATH,"report-group-3","codes_01_energy_demand", "thermal_properties.csv"),index=False)
```

```{r table-widget, echo=F, eval=T, fig.cap= 'Thermal properties of the buildings'}
#| label: fig-thermalProp

thermal_properties <- read.csv("codes_01_energy_demand/thermal_properties.csv")

library(DT)

datatable(thermal_properties, options = list(pageLength = 5, scrollX=TRUE)            
)
```

## Impact of renovation and indoor temperature {#subsec:ksun}

Having determined $k_\text{th}$ and $k_\text{sun}$, a sensitivity analysis can be performed to study their impact on the energy consumption of the buildings. On one hand, $k_\text{th}$, which represents the leakage losses, should be decreased and on the other hand, $k_\text{sun}$, which characterizes the solar gains, needs to be increased. The solar gains can be increased by changing the absorptivity of the building, i.e. either by replacing the building’s coating or using a different paint on the exterior façade. As for the constraint on $k_\text{th}$, it is the sum of the ventilation and the building losses : $k_\text{th}=U_\text{env}+\dot{m_\text{air}}Cp_\text{air}$. The air renewal rate meeting requirements to avoid high $CO_\text{2}$ concentration, it is difficult to change this value to decrease the leakage losses. Therefore, one must decrease the value of $U_\text{env}$. To do so, the building isolation can be improved by changing the thickness or the material of the walls and windows. However, this is linked to high renovation cost and to long labor duration compared to the possible gains by changing $k_\text{sun}$. Increasing $k_\text{sun}$ by 25, 50 and 75 $\%$, one can influence the evolution of the heat demand:

```{r ksun-var, out.width='100%', fig.align='center', fig.cap='Variation of Qheating with different ksun', echo=F, fig.show='hold'}
#| label: ksun-var
knitr::include_graphics('Figures/k_sun_var.png')
```

The figure shows, that during seasons when the irradiation is low (winter and fall) and when the heating demand is at its lowest (summer), the variation of $k_\text{sun}$ does not change significantly the value of the heating demand. Nevertheless, during spring where the impact of $k_\text{sun}$ on the heating demand is the highest, one can see that the variation of $Q_\text{heating}$ is the greatest. Zooming on the picture, one notices that the yellow points representing the heating demand of the highest increase in $k_\text{sun}$ are the lowest.

## Clustering {#subsec:clustering}

Now that the buildings are physically characterized, it is possible to solve the energy demand equation @eq-building-balance. However, for a yearly optimization of this equation, this would mean optimizing for 8760 different demands. Reducing the data might help run a more efficient optimization. Clustering helps defining typical time periods that are representative enough of the heat loads. To do so, clustering of the weather data is performed and will be used to solve a reduced energy balance equation. 

### Weather Data preprocessing

Before starting the clustering, the temperature and irradiance data are split in three groups:

- Type A: timesteps were the buildings are used (Monday to Friday 7am to 9pm) and the external
temperature is below the cut off temperature of 16 °C.
- Type B: the exact opposite of type A leaving the timesteps when the buildings are not used (night,
weekend) and the external temperature is greater than 16 °C.
- Type O: the coldest hour of the year as extreme timestep.


```{python, echo=F, eval=T}
#| label: weather cluster plotting

#Add 'Type' column
weather = fct1.preprocess_data(weather, profile_elec)

# Create the initial figure
fig_weather = px.scatter(weather, x=weather.index, y='Temp', color='Type', title='Weather data - Temperature (processed)',
                         labels={'Temp': 'Temperature [°C]', 'Hours': 'Hour'})

# Use a context manager to delay the display
with fig_weather.batch_update():

    fig_weather.update_xaxes(title='Hour')

    # Add horizontal line at 16°C
    fig_weather.add_shape(type='line', x0=0, x1=len(weather), y0=16, y1=16, line=dict(color='red'))

    # Write "16°C" next to the line
    fig_weather.add_annotation(text='16°C', xref='paper', yref='y', x=0, y=17, showarrow=False, font=dict(color='red'))

    # Show the legend
    fig_weather.update_layout(legend_title_text='Type')

fig_weather = px.scatter(weather, x=weather.index, y='Irr', color='Type', title='Weather data - Irradiation (processed)',
                         labels={'Irr': 'Irradiation [W/m2]', 'Hours': 'Hour'})
                         
fig_weather.show()
```

### Method selection

Clustering via Machine Learning is now widely spread and lot of tools allow for easy implementation. Using Sci-Kit, the weather data are clustered using unsepervised algorithm. Kmeans, Spectral clustering and agglomerate clustering are probed. A common metric used to asses of the relevancy of such clustering is the Sum of Squared Errore (SSE). The visualisation of the clustering for $k=10$ clusters is shown in the figure (@fig-clusteringComp). The SSE is summarized in the table (@tbl-clusteringSSE).

_Note:_ the data has been normalized to perform the clustering, and reversed to plot

```{python, echo = F, eval=T}
#| label: fig-clusteringComp
#| fig-cap: Different clustering method results

n_clusters = 10
kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init='auto')
spectral = SpectralClustering(assign_labels='discretize', n_clusters=n_clusters, random_state=0)
agglo = AgglomerativeClustering(n_clusters=n_clusters)

weather_clustering = WeatherClustering(weather, n_clusters, profile_elec)
weather_clustering.preprocess_data()

fig, axs = plt.subplots(1, 3, figsize=(15, 5))

titles = ['Spectral Clustering','Agglomerative Clustering','KMeans Clustering']

fig.suptitle(f'Clustering comparison, {n_clusters} clusters')

for i, method in enumerate([spectral, agglo, kmeans]):
    weather_clustering.clustering(method)
    weather_clustering.plot_clusters(axs[i])
    axs[i].set_title(titles[i])

plt.show()
```

|     | Spectral | Agglo | Kmeans |
|-----|----------|-------|--------|
| SSE | 241      |  236  |  196   |
: Clustering SSE {#tbl-clusteringSSE}


The most promising method is thus the Kmeans algorithm, which will be selected to define typical operating conditions.

### Hyperparameter $k$ selection 

Choosing to work with Kmeans clustering still leaves room to fiddle with the number of cluster to choose. A common way to choose this parameter is the use of the "Elbow method", which allows to select the right number of clusters doing a compromise between the precision and the number of clusters. Inspection of (@fig-elbowMethod) allows to think that $k=6$ is a relatively good trade off.

```{python, echo = F, eval=T, label = 'fig-elbowMethod', fig.cap='Elbow method'}
#| label: fig-elbowMethod
#| 
fct1.elbow_method(weather_clustering.data,15)
```

### Clustering results
The result of the clustering are shown below. 

```{python, echo=F, eval=T, results = 'show'}
#| label: perform clustering

weather, cluster = fct1.clusteringCorentin(weather,n_clusters=6)

Q_th_cluster = pd.DataFrame(columns=buildings.Name)
Q_th_extreme = pd.Series(index=buildings.Name)

# Extract thermal_properties of buildings
A_th            = thermal_properties['FloorArea']   # m^2
k_th            = thermal_properties['k_th']        # kW/m^2 K
k_sun           = thermal_properties['k_sun']       # -
specQ_people    = thermal_properties['specQ_people']# kW/m^2
specElec        = thermal_properties['specElec']    # kW/m^2

T_cluster = cluster['Temp']
irr_cluster = cluster['Irr']
T_extreme = weather['Temp'].iloc[-1]
irr_extreme = weather['Irr'].iloc[-1]

# Recompute thermal load for each cluster using cluster centers
for building_id in buildings['Name']:
    Q_th_cluster[building_id] = A_th[building_id]*(k_th[building_id]*(T_int-(T_cluster+273)) - k_sun[building_id]*irr_cluster/1000 - specQ_people[building_id] - specElec[building_id]*f_el) # [kWh]
    Q_th_extreme[building_id] = A_th[building_id]*(k_th[building_id]*(T_int-(T_extreme+273)) - k_sun[building_id]*irr_extreme/1000 - specQ_people[building_id] - specElec[building_id]*f_el) # [kWh]
Q_th_cluster.loc[len(Q_th_cluster)] = Q_th_extreme

# Keep only Medium temps buildings (Year 1)
Q_th_cluster = Q_th_cluster[buildings['Name'].loc[buildings.Year == 1]]

# Sum and multiply by operating hours the (positive) heating loads
cluster['Q_th'] = Q_th_cluster[Q_th_cluster >= 0].sum(axis=1)*cluster['Hours']

cluster.to_csv(os.path.join(PATH,"report-group-3","codes_01_energy_demand", "clusters_data.csv"),index=False)
```

```{python, echo=F, eval = T}
#| label: plot clustering 
# Scatter plot for weather data type A
fig = px.scatter(weather.loc[weather['Type']=='A'], x='Temp', y='Irr', color="Cluster", 
                 title='Weather data type A', labels={'Temp': 'Temperature [°C]', 'Irr': 'Irradiation [W/m2]'})
cluster_trace = go.Scatter(
    x=cluster.iloc[:, 0],
    y=cluster.iloc[:, 1],
    mode='markers',
    marker=dict(color='red', size=20, opacity=0.8),
    name='Cluster Centroids'
)
fig.add_trace(cluster_trace)

cluster.rename(columns={
    'Temp': 'Temperature [°C]',
    'Irr': 'Irradiance [W/m2]',
    'hours': 'Operating time [h]'
}, inplace=True)
cluster = cluster.round(2)
html_table = cluster.to_html()
title_html = '<h2 style="text-align:center;">Cluster Centroids</h2>'
final_html = title_html + html_table
HTML(final_html)
```

\begin{comment}
Here you report what you have done and found concerning part 1. It includes the parametric estimations of the electricity demand, the heat gains from the people, the Kth and Ksun values using Newton_Raphson and the typical period clustering. All .qmd files present in the main folder are read while rendering the book. The four folders called **codes** are here to make your calculations. The files contained in these folders are not read while rendering the book. **We advice you to work and develop your models in the subfolders only**. Then you will use the .qmd in the main folder to report the models and data generated in the sub-folders. 

**Important note: when you are working on your functions and models, open VScode at the level of the subfolders to avoid path issues!**

## Objective

The main objective of this part of the project is to **analyze the energy demands of the EPFL campus**, with a focus on the heating demands and design characteristics of the various buildings on-site. Understanding the thermal design of the buildings (wall properties, heat gains, thermal losses) is important for a proper control of the amount of energy required to ensure thermal comfort throughout the year. To this end you are asked to: 

 1. calculate the thermal gains from people and electronic appliances, based on the occupancy profiles of the buildings 
 2. estimate the thermal properties of the buildings based on the annual heating demand 
 3. Identify the most frequent and extreme working conditions (typical periods)
 4. Derive the hourly heating demand over the whole year for the buildings

In the reminaing of the project, you will use the results obtained at the end of this part.

## Code Guidelines

For this **Part 1** you have at your disposition:

 - Two .csv files *Buildings.csv* and *Weather.csv* containing the data to process
 - A python file *NR_functions.py* where you will develop your functions to solve part 1
 - A **book** in **Quarto** *01.00-Energy_demand.qmd* (the file where you are now) where you will call your functions and data to report the results

Most of the development will take place in the python file *NR_functions.py*. Once your functions are running well, you will use to this .qmd file for the reporting and call your functions to generate and plot results.

In *NR_functions.py*, the data are imported using [Pandas](http://pandas.pydata.org) library, and we suggest you to make your calculations using the [Numpy](http://www.numpy.org) library. In addition to this, you are welcome to use any other libraries or toolboxes for the project. Regarding the plots, we advise you to use either [Matplotlib](https://matplotlib.org/), [Seaborn](https://seaborn.pydata.org/) or [Plotly Python](https://plotly.com/python/). **Even though we propose a certain structure for the function, you are totally free to restructure them the way you prefer. It only aims to help you start with the project by providing skeleton functions. If you find it more convenient to do it very differently, you are welcome to do so.**

Before starting, check that your venv folder has been created the first time you have rendered the index.qmd. 


## Reporting
In the following, we provide you some piece of codes to integrate your functions and data in the report. 
In the first chunk, you specify the path to your venv folder. 



If some python packages are missing, you can install them yourself in the venv. Below is an example. Don't forget to comment the chunk once the package has been installed in your venv (echo=F). Note that here we are using an R chunk to do this. You could as well use the terminal.
```{r, eval=F}
py_install("seaborn")
```


Load the data:


Overview of the Buildings dataframe

```{python table plot, echo=F}
import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=list(buildings.columns),
                fill_color='lightskyblue',
                line_color='darkslategray',
                align='center'),
    cells=dict(values=[buildings[col] for col in buildings],
               fill_color='white',
               line_color='darkslategray',
               align='center'))
])
fig.update_layout(width=800, height=700)

```


## TASK 1 - Calculation of the internal heat gains (people & appliances)

Using python chunks and functions in NR_functions.py, calculate the heat gains from people and appliances.

Then find the values of kth and ksun for every building. Finally, store all your results in a new .csv file to use them later. 

### Internal gains - People

```{python, echo=T, results='hide'}
# Generate the yearly occupancy profile of the buildings
occ_profile = fct1.occupancy_profile()
```



### Internal gains - Electronic appliances


## TASK 2 - Calculation of the building thermal properties (k<sub>th</sub> and k<sub>sun</sub>)

Parameters for Newton-Raphson iterations


Mean values computation and proper initialisation

## TASK 4 - Clustering

The clustering should be performed on weather data, in our case external temperature and irradiation. Remind that it is highly recommended to normalize the data before clustering.

It is required to apply at least two clustering methods and to compare the quality of the generated typical periods. It is your choice to select the preferred methodology to reduce the data. Give some visual representations of your clustering results.

Optional: To conclude this first part, you can plot the hourly heat demand of the campus based on the internal heat gains, k_sun, k_th and your typical periods.
\end{comment}